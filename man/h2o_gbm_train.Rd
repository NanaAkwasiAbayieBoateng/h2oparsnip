% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/boost_tree.R
\name{h2o_gbm_train}
\alias{h2o_gbm_train}
\title{Wrapper for training a h2o.gbm model as part of a parsnip `boost_tree`
h2o engine}
\usage{
h2o_gbm_train(
  formula,
  data,
  ntrees = 50,
  max_depth = 5,
  min_rows = 10,
  learn_rate = 0.1,
  sample_rate = 1,
  col_sample_rate = 1,
  ...
)
}
\arguments{
\item{formula}{formula}

\item{data}{data.frame of training data}

\item{...}{other arguments not currently used}

\item{l2}{numeric, l2 regulation parameter, default = 0}

\item{hidden_dropout_ratios}{dropout ratio for a single hidden layer (default
= 0)}

\item{hidden}{integer, number of neurons in the hidden layer (default = 200)}

\item{epochs}{integer, number of epochs (default = 10)}

\item{activation}{character, activation function. Must be one of: "Tanh",
"TanhWithDropout", "Rectifier", "RectifierWithDropout", "Maxout",
"MaxoutWithDropout". Defaults to "Rectifier. If `hidden_dropout_ratios` > 0
then the equivalent activation function with dropout is used.}
}
\value{
evaluated h2o model call
}
\description{
Wrapper for training a h2o.gbm model as part of a parsnip `boost_tree`
h2o engine
}
